
\section{Experiments}
\label{sec:experiments}

Following standard benchmarks for variational inference in deep
learning, we learn generative models of images. In particular, we
learn the \gls{DLGM}~\citep{rezende2014stochastic}, a
layered hierarchy of Gaussian random variables following neural network
architecures, and the recently proposed
\gls{DRAW}~\citep{gregor2015draw}, a latent attention model that iteratively
constructs complex images using a recurrent architecture and
a sequence of variational auto-encoders~\citep{kingma2014autoencoding}.

For the learning rate we apply a version of
RMSProp~\citep{tieleman2012rmsprop}, in which we scale the value with
a decaying schedule $1/t^{1/2+\epsilon}$ for
$\epsilon>0$. We fix the
size of variational data to be $500$ across all experiments
and set the latent input dimension equal to the number of
latent variables.

\subsection{Binarized MNIST}

\begin{table}[tb]
\centering
\begin{tabular}{lcc}
\toprule
Model & $-\log p(\mbx)$ & $\le$
\\
\midrule
DLGM + {VAE} [\textcolor{MidnightBlue}{1}] &    & 86.76\\
{DLGM} + HVI (8 leapfrog steps) [\textcolor{MidnightBlue}{2}] & 85.51
& 88.30\\
{DLGM} + NF ($k=80$) [\textcolor{MidnightBlue}{3}] &    & 85.10\\
EoNADE-5 2hl (128 orderings) [\textcolor{MidnightBlue}{4}] & 84.68\\
DBN 2hl [\textcolor{MidnightBlue}{5}] & $84.55$\\
DARN 1hl [\textcolor{MidnightBlue}{6}] & $84.13$\\
Convolutional VAE + HVI [\textcolor{MidnightBlue}{2}] & 81.94 & 83.49\\
{DLGM} 2hl + IWAE ($k=50$) [\textcolor{MidnightBlue}{1}] &    & 82.90\\
DRAW [\textcolor{MidnightBlue}{7}] &    & 80.97\\
\midrule
{DLGM} 1hl + \gls{VGP} &    & 83.64\\
{DLGM} 2hl + \gls{VGP} &    & 81.90\\
DRAW + \gls{VGP} &    & \textbf{80.11}\\
\bottomrule
\end{tabular}
\caption{Negative predictive log-likelihood for binarized MNIST.
Previous best results are
[1]~\citep{burda2015importance},
[2]~\citep{salimans2015markov},
[3]~\citep{rezende2015variational},
[4]~\citep{raiko2014iterative},
[5]~\citep{murray2009evaluating},
[6]~\citep{gregor2014deep},
[7]~\citep{gregor2015draw}%
.}
\label{table:mnist}
\end{table}

The binarized MNIST data set~\citep{salakhutdinov2008quantitative}
consists of 28x28 pixel images with binary-valued outcomes.  Training
a \gls{DLGM}, we apply two stochastic layers of 100 random variables
and 50 random variables respectively, and in-between each stochastic
layer is a deterministic layer with 100 units using tanh
nonlinearities. We apply mean-field Gaussian distributions for the
stochastic layers and a Bernoulli likelihood. We train the \gls{VGP}
to learn the \gls{DLGM} for the cases of one stochastic layer and
two stochastic layers.

For \gls{DRAW}~\citep{gregor2015draw}, we augment the
mean-field Gaussian distribution originally used to generate the latent samples
at each time step with the \gls{VGP}, as it places a complex
variational prior over its
parameters. The encoding
recurrent neural network now outputs variational data (used for the
variational model) as well as mean-field
Gaussian parameters (used for the auxiliary model). We use the same architecture hyperparameters as in
\citet{gregor2015draw}.

After training we evaluate test set log likelihood, which are lower
bounds on the true value. See \mytable{mnist} which reports both
approximations and lower bounds of $\log p(\mbx)$ for various methods.
The \gls{VGP} achieves the highest known results on
log-likelihood using \gls{DRAW}, reporting a value of \textbf{-80.11}
compared to the original highest of {-80.97}.
The \gls{VGP} also achieves the highest known results among the class of
non-structure exploiting models using the \gls{DLGM}, with a value of
{-81.90} compared to the previous best of {-82.90} reported by \citet{burda2015importance}.

\if0
\subsection{CIFAR-10}
\PP
CIFAR-10 is a collection of natural images consisting of 50,000
training and 10,000 test RGB images of size 3x32x32
pixels~\citep{krizhevsky2009learning}.

\begin{figure}[t]
\begin{minipage}{\textwidth}
\begin{minipage}[!t]{.45\textwidth}
\centering
\begin{tabular}{ll}
\toprule
Model & $-\log p(\mbx)$
\\
\midrule
DLGM + NF ($k=10$) [\textcolor{MidnightBlue}{3}] & -320.7\\
DRAW [\textcolor{MidnightBlue}{8}] & ?\\
\PP other papers? \\
\midrule
DRAW + \gls{VGP} & ?\\
\bottomrule
\end{tabular}
\caption{Negative predictive log-likelihood for CIFAR-10.}
\label{table:cifar}
\end{minipage}
\begin{minipage}[!t]{.54\textwidth}
\centering
\PP
\caption{Generated images from DRAW with a \gls{VGP} (top), and DRAW
with the default variational model (bottom). The \gls{VGP} leads to
visually \PP more tractable images (see that one paper on the
terminology here).}
\label{fig:cifar}
\end{minipage}
\end{minipage}
\end{figure}
\fi

\subsection{Sketch}
\begin{figure}[t]
\begin{minipage}{\textwidth}
\begin{minipage}[!t]{.45\textwidth}
\centering
\begin{tabular}{lll}
\toprule
Model & Epochs & $\le -\log p(\mbx)$
\\
\midrule
\gls{DRAW} & 100 & 526.8\\
           & 200 & 479.1\\
           & 300 & 464.5\\
\gls{DRAW} + \gls{VGP} & 100 & \textbf{475.9}\\
                       & 200 & \textbf{430.0}\\
                       & 300 & \textbf{425.4}\\
\bottomrule
\end{tabular}
\captionof{table}{Negative predictive log-likelihood for Sketch, learned over hundreds
of epochs over all 18,000 training examples.}
\label{table:sketch}
\end{minipage}
\hfill
\begin{minipage}[!t]{.52\textwidth}
\centering
\includegraphics[width=\columnwidth]{img/sketch_300.png}
\includegraphics[width=\columnwidth]{img/sketch_draw.png}
\captionof{figure}{Generated images from \gls{DRAW} with a \gls{VGP} (top), and
\gls{DRAW} with the original variational auto-encoder (bottom). The
\gls{VGP} learns texture and sharpness, able to sketch more complex shapes.}
\label{fig:sketch}
\end{minipage}
\end{minipage}
\end{figure}
As a demonstration of the \gls{VGP}'s complexity for learning
representations, we also examine
the Sketch data set~\citep{eitz2012hdhso}. It consists of 20,000 human
sketches equally distributed over 250 object categories. We partition
it into 18,000 training examples and 2,000 test examples. We fix
the architecture of \gls{DRAW} to
have a 2x2 read window, 5x5 write attention window, and
64 glimpses---these values were selected using a coarse grid search
and choosing the set which lead to the best training log likelihood.
For inference we use the original auto-encoder version as well as the
augmented version with the \gls{VGP}.

See \mytable{sketch}. \gls{DRAW} with the \gls{VGP}
achieves a significantly better lower bound, performing better than
the original version which has seen state-of-the-art success in many computer
vision tasks. (Until the results presented here, the results from the
original \gls{DRAW}
were the best reported performance for this data set.). Moreover,
the model inferred using the \gls{VGP} is able to generate more
complex images than the original version---it not only performs better
but maintains higher visual fidelity.


